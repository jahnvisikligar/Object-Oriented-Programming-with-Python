{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahnvisikligar/Object-Oriented-Programming-with-Python/blob/main/Markov_chains_and_N_grams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTznHbHuRNJw"
      },
      "source": [
        "# Markov chains and N-Grams implementation\n",
        "\n",
        "In this project of text generation we will be implementing Markov chains and N-grams technique by using source material from [Project Gutenberg](https://www.gutenberg.org/)). The source code is a culmination of inspiration from various online sources which have been tried to acknowledge on timely basis during the execution of this project.\n",
        "\n",
        "In the initial steps the load the complete book. Please note that few alterations have been made to the .txt file so as to avaoid irrelevant data to be removed."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "P_QjgXlUfZjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07c39ce-bdf6-44f8-f198-37dfc79cc6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzpYJ-L6RNJ0"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/the_time_machine.txt') as text_file:\n",
        "    the_time_machine = text_file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5XxqVXWRNJ1"
      },
      "source": [
        "Storing the entire text of the novel in the string 'the time machine.' This means we can begin working with the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iReeerFBRNJ1",
        "outputId": "f0a21d18-f31d-4b39-a282-acb29a4f3114",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Time Machine\n",
            "\n",
            "An Invention\n",
            "\n",
            "by H. G. Wells\n",
            "\n",
            " I.\n",
            " Introduction\n",
            "\n",
            "\n",
            "The Time Traveller (for so it will be convenient to speak of him) was\n",
            "expounding a recondite matter to us. His pale grey eyes shone and\n",
            "twinkled, and his usually pale face was flushed and animated. The fire\n",
            "burnt brightly, and the soft radiance of the incandescent lights in the\n",
            "lilies of silver caught the bubbles that flashed and passed in our\n",
            "glasses. Our chairs, being his patents, embraced and caressed us rather\n",
            "than submitted to be sat upon, and there was that luxurious\n",
            "after-dinner atmosphere, when thought runs gracefully free of the\n",
            "trammels of precision. And he put it to us in this way—marking the\n",
            "points with a lean forefinger—as we sat and lazily admired his\n",
            "earnest\n"
          ]
        }
      ],
      "source": [
        "print(the_time_machine[:750])  # Print the first 750 characters of the novel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSu2MYB5RNJ2"
      },
      "source": [
        "Notice how I use a technique called \"slicing\" to quickly tell Python the boundary for the characters to return. The `[:750]` means start at character 0 up to character 750 (a clearer way to put it would be `[0:750]`.\n",
        "\n",
        "Note: The colon separates the lower and upper boundary, if none is given [as in my example] then the beginning [i.e. 0] is assumed).\n",
        "\n",
        "The built-in `len` function is also very useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpgKzMhCRNJ2",
        "outputId": "f47328a9-0394-4194-ddb0-292deafa7ecb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179298"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(the_time_machine)  # to display number of characters (as in letters in the novel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rHrn3tsRNJ2"
      },
      "source": [
        "We will be using 'split' method to rmeove whitespaces(new line, tab, space, etc..). This would help in easily compute the word count."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzWp88UpRNJ3",
        "outputId": "ef09b9dd-e9a3-45ab-fa77-d441356647bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32385"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "all_the_words_in_the_novel = the_time_machine.split()  # Split the novel by whitespace.\n",
        "len(all_the_words_in_the_novel)  # The length of all_the_words_in_the_novel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiGVu3xuRNJ3"
      },
      "source": [
        "Return a Python list of the first 50 words of the novel like this (notice how I'm using \"slicing\" again):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4gIA3RqRNJ3",
        "outputId": "42a2fc0f-e214-4d5a-e8c6-fa5718740cb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffThe',\n",
              " 'Time',\n",
              " 'Machine',\n",
              " 'An',\n",
              " 'Invention',\n",
              " 'by',\n",
              " 'H.',\n",
              " 'G.',\n",
              " 'Wells',\n",
              " 'I.',\n",
              " 'Introduction',\n",
              " 'The',\n",
              " 'Time',\n",
              " 'Traveller',\n",
              " '(for',\n",
              " 'so',\n",
              " 'it',\n",
              " 'will',\n",
              " 'be',\n",
              " 'convenient',\n",
              " 'to',\n",
              " 'speak',\n",
              " 'of',\n",
              " 'him)',\n",
              " 'was',\n",
              " 'expounding',\n",
              " 'a',\n",
              " 'recondite',\n",
              " 'matter',\n",
              " 'to',\n",
              " 'us.',\n",
              " 'His',\n",
              " 'pale',\n",
              " 'grey',\n",
              " 'eyes',\n",
              " 'shone',\n",
              " 'and',\n",
              " 'twinkled,',\n",
              " 'and',\n",
              " 'his',\n",
              " 'usually',\n",
              " 'pale',\n",
              " 'face',\n",
              " 'was',\n",
              " 'flushed',\n",
              " 'and',\n",
              " 'animated.',\n",
              " 'The',\n",
              " 'fire',\n",
              " 'burnt']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "all_the_words_in_the_novel[:50] #list of 50 words in the novel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVxcxR7mRNJ4"
      },
      "source": [
        "Analysis if the full content has been done.\n",
        "\n",
        "Our main objective is to generate prose that's based on H.G.Wells. The most obvious way to analyse the novel is to look at how the words flow together. If we could figure that out, we could write some code that, given N previous words, would figure out a likely *new* word to follow.\n",
        "\n",
        "The N-gram is a technique for grouping adjacent words together (where N is the number of words in each group). It's the kind of thing that's obvious but may be difficult to explain... so here's an example.\n",
        "\n",
        "Following output can be estimated for If \n",
        "N = 3,\n",
        "\n",
        "\"The Time Machine\"\n",
        "\n",
        "\"An Invention by\"\n",
        "\n",
        "\n",
        "N = 2,\n",
        "\n",
        "\"The Time\" \n",
        "\n",
        "\"Machine An\" \n",
        "\n",
        "\"Invention by\" \n",
        "\n",
        "(and so on...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPdvieRtRNJ4"
      },
      "outputs": [],
      "source": [
        "def find_ngrams(input_list, n):\n",
        "  return zip(*[input_list[i:] for i in range(n)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-YLFGPRRNJ4"
      },
      "source": [
        "We will be using python's builtin zip function. The zip function will take in a list of iterables and create a new list of tuples where each list will contain inputs of the elements accordingly.\n",
        "\n",
        "The zip function has been explained in detail in this blog post:(http://locallyoptimal.com/blog/2013/01/20/elegant-n-gram-generation-in-python/).\n",
        "\n",
        "We already have the list 'all the words in the novel' that should be passed into the function. The second argument, 'n' should be the n-N gram's value. The end result will be a collection of all the n-grams from The Time Machine. Let's begin with N = 3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb3821YERNJ5",
        "outputId": "dcb1cf7a-c85f-4261-d958-1eb120ba16c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('\\ufeffThe', 'Time', 'Machine'),\n",
              " ('Time', 'Machine', 'An'),\n",
              " ('Machine', 'An', 'Invention'),\n",
              " ('An', 'Invention', 'by'),\n",
              " ('Invention', 'by', 'H.'),\n",
              " ('by', 'H.', 'G.')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "ngrams = list(find_ngrams(all_the_words_in_the_novel, 3))  # get the n-grams as a list; N=3\n",
        "ngrams[:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU_I9bODRNJ5"
      },
      "outputs": [],
      "source": [
        "N = 3  #assuming we want to use n-grams of three."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlA2bX0hRNJ6"
      },
      "outputs": [],
      "source": [
        "n_grams = {}  # creating an empty dictionary to contain our n-grams and list of following words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWjMGKy8RNJ6"
      },
      "outputs": [],
      "source": [
        "for ngram in find_ngrams(all_the_words_in_the_novel, N + 1):  #populating the dictionary.\n",
        "    key_ngram = ngram[:N]  #using only the N number of words for our n-gram.\n",
        "    following_word = ngram[-1]  #N+1th word is the following word.\n",
        "    word_list = n_grams.get(key_ngram, [])  #Get the current list of following words (or a new one if it doesn't exist).\n",
        "    word_list.append(following_word)  #Append the following_word to the list.\n",
        "    n_grams[key_ngram] = word_list  # Update the entry for the n-gram in the dict with the updated word_list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akyV2hjDRNJ6"
      },
      "source": [
        "If we choose an starting n-gram at random, then just keep generating a new word some arbitrary number of times. The output will start with the three words of the first (randomly selected) n-gram and we just need to append each new word until we tell it to stop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAcWfCttRNJ6",
        "outputId": "e3840e09-2d8f-4e34-8ace-d3b794c62041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I would make the descent without further waste of time, and started out in the early morning towards a well near the ruins of granite and aluminium. “Little Weena ran with me. She danced beside me to the well, but when she saw me lean over the mouth and look downward, she seemed strangely disconcerted. ‘Good-bye, little Weena,’ I said, kissing her; and'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import random  # The random module contains lots of helpful functions to choose things at random.\n",
        "\n",
        "seed_ngram = random.choice(list(n_grams.keys()))  # Choose a random seed n-gram from a list of all n-grams in the novel.\n",
        "output = list(seed_ngram)  # Create the output with a list of the words from the first n-gram.\n",
        "\n",
        "for i in range(60):  # Make 32 more new words...\n",
        "    next_word = random.choice(n_grams[seed_ngram])  # Choose a next word from the list associated with the seed n-gram.\n",
        "    output.append(next_word)  # Append the randomly selected next word to the output.\n",
        "    new_ngram = list(seed_ngram[1:])  # Create a new n-gram from the current seed n-gram (without its first item)\n",
        "    new_ngram.append(next_word)  # Append the next word to the new n-gram thus completing the new n-gram.\n",
        "    seed_ngram = tuple(new_ngram)  # Make the new n-gram the seed n-gram for the next iteration.\n",
        "\n",
        "' '.join(output)  # Join the words in the output list with a space inbetween."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-Ia48fnRNJ7",
        "outputId": "a8c6e757-c948-44b5-ea71-f0e7c3b7f82d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('His', 'pale', 'grey'),\n",
              " ('The', 'fire', 'burnt'),\n",
              " ('Our', 'chairs,', 'being'),\n",
              " ('And', 'he', 'put'),\n",
              " ('I', 'shall', 'have'),\n",
              " ('The', 'geometry,', 'for'),\n",
              " ('You', 'will', 'soon'),\n",
              " ('You', 'know', 'of'),\n",
              " ('They', 'taught', 'you'),\n",
              " ('Neither', 'has', 'a')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "stop_characters = \".?!\"  # Characters that end sentences.\n",
        "ignore_words = [\"Mr.\", \"Mrs.\", \"Miss.\", \"Rev.\", \"Dr.\", \"H.\", \"G.\", \"I.\" ,\"II.\", \"III.\", \"IV.\", \"V.\", \"VI.\", \"VII.\", \"VIII.\",\"IX.\", \"X.\", \"XI.\",\"XII.\", \"XIII.\", \"XIV.\", \"XV.\", \"XVI\"]  # Words ending in a full stop but are not the end of a sentence.\n",
        "\n",
        "all_ngrams = find_ngrams(all_the_words_in_the_novel, N + 1)  # All the ngrams (N+1) in the novel.\n",
        "\n",
        "open_n_grams = []  # Currently empty, will contain all valid opening n-grams.\n",
        "\n",
        "for ng in all_ngrams:  # Loop over ALL the ngrams to work out if they're valid opening n-grams.\n",
        "    if ng[0][-1] in stop_characters:  # Is the final character of the first word of the n-gram a stop character?\n",
        "        # If the first word isn't in the list of ignore_words AND the second word either starts with an upper-case\n",
        "        # character or it starts with a quotation mark (\")...\n",
        "        if ng[0] not in ignore_words and (ng[1][0].isupper() or ng[1][0] == '\"'):\n",
        "            # Strip off the first word, and add the remaining N words as a valid opening n-gram. \n",
        "            open_n_grams.append(ng[1:]) \n",
        "\n",
        "open_n_grams[:10]  # Output the first ten opening ngrams to check they look OK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsLKG_0xRNJ7"
      },
      "source": [
        "Getting the `open_n_grams` involves several considerations:\n",
        "\n",
        "* We need to identify detect when there's the end of a sentence (so the following words will become part of an opening n-gram). We detect by matching against common `stop_characters` which indicate the end of a sentence.\n",
        "* The start of a sentence must begin with a capitalised letter or an opening quotation mark.\n",
        "\n",
        "The actual process of creating opening n-grams of length N, actually involves using n-grams of N+1. Say N is 3 then we need all the 4 word n-grams in the novel so we can act on them like this:\n",
        "\n",
        "* Imagine a 4 word n-gram: `carefully. I shall have` (taken from the `the_time_machine.txt` file.\n",
        "* Firstly, checking the first word `carefully.` has a final character which is a stop character (it does).\n",
        "* Second, check it's not in the tricky words to ignore (it's not).\n",
        "* Third, so far so good, so check the second word to see if it either starts with a capital letter (it does not) or a quotation mark (it does).\n",
        "* Fourth, we've found an n-gram that we can use! So, remove the first word (`carefully.`) leaving us with an n-gram of length N: `I shall have`\n",
        "* Add this n-gram to the `open_n_grams` list.\n",
        "\n",
        "If any of the various checks described above are unsuccessful, then that particular n-gram is ignored and we move onto the next N+1 n-gram.\n",
        "\n",
        "To generate a new seed for starting a sentence we can just use `random.choice` on the `open_n_grams` list to get an appropriate n-gram:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh3ZmMN6RNJ7",
        "outputId": "8860b200-8cc8-4501-e295-db7dcf4f85ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('It', 'must', 'have')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "seed_ngram = random.choice(open_n_grams)\n",
        "seed_ngram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP-xPh-ORNJ7"
      },
      "outputs": [],
      "source": [
        "def makesentence(word_length):\n",
        "    \"\"\"\n",
        "    Return a sentence of approximately word_length length.\n",
        "    \"\"\"\n",
        "    seed_ngram = random.choice(open_n_grams)\n",
        "    result = list(seed_ngram)\n",
        "    while len(result) < word_length:\n",
        "        next_word = random.choice(n_grams[seed_ngram])\n",
        "        result.append(next_word)\n",
        "        new_ngram = list(seed_ngram[1:])\n",
        "        new_ngram.append(next_word)\n",
        "        seed_ngram = tuple(new_ngram)\n",
        "    return tuple(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbE7NTiKRNJ7"
      },
      "source": [
        "checking the basic version working:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w0dCkSjRNJ8",
        "outputId": "ae434ee2-b630-4113-91ff-6df96e5b04cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'But it occurred to me even then, that'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "' '.join(makesentence(8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzWSlBD0RNJ9"
      },
      "outputs": [],
      "source": [
        "def make_next_word(seed_ngram, quote_flag=False):\n",
        "    \"\"\"\n",
        "    Return the next word and n-gram given a seed_ngram. If quote_flag is True, allow words that end in\n",
        "    a quotation mark.\n",
        "    \"\"\"\n",
        "    candidate_words = n_grams[seed_ngram]  # possible next words.\n",
        "    if not quote_flag:  # Throw away words that end with a quotation mark.\n",
        "        candidate_words = [word for word in candidate_words if not word[-1] == '\"']\n",
        "    if not candidate_words:  # If we end up with no candidate words, just reset them.\n",
        "        candidate_words = n_grams[seed_ngram]\n",
        "    # Continue as in previous examples. \n",
        "    next_word = random.choice(candidate_words)\n",
        "    new_ngram = list(seed_ngram[1:])\n",
        "    new_ngram.append(next_word)\n",
        "    return next_word, tuple(new_ngram)\n",
        "\n",
        "\n",
        "def makesentence(word_length):\n",
        "    \"\"\"\n",
        "    Return a sentence of approximately word_length length.\n",
        "    \"\"\"\n",
        "    quote_flag = False  # Indicates if the sentence contains an opening quotation mark.\n",
        "    seed_ngram = random.choice(open_n_grams)\n",
        "    result = list(seed_ngram)\n",
        "    for word in result:  # Check the words from the opening n-gram for opening quotes.\n",
        "        if word[0] == '\"':\n",
        "            quote_flag = True\n",
        "            break\n",
        "    while len(result) < word_length - 1:\n",
        "        next_word, seed_ngram = make_next_word(seed_ngram)\n",
        "        result.append(next_word)\n",
        "        # The following two if statements check the word and ensure the quote_flag is correctly set, if needed.\n",
        "        if next_word[0] == '\"':  # [0] means the first character.\n",
        "            quote_flag = True\n",
        "        if next_word[-1] == '\"':  #[-1] means the final character.\n",
        "            quote_flag = False\n",
        "    while True:\n",
        "        ending_words = [word for word in n_grams[seed_ngram] if word[-1] in stop_characters and word not in ignore_words]\n",
        "        if ending_words:\n",
        "            result.append(random.choice(ending_words))\n",
        "            break\n",
        "        else:\n",
        "            next_word, seed_ngram = make_next_word(seed_ngram) \n",
        "            result.append(next_word)\n",
        "            # Since we still don't have a word to end the sentence, the same quote-checking as above needs to\n",
        "            # happen to ensure speech marks remain balanced.\n",
        "            if next_word[0] == '\"':\n",
        "                quote_flag = True\n",
        "            if next_word[-1] == '\"':\n",
        "                quote_flag = False\n",
        "    return tuple(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85zsLrbyRNJ9"
      },
      "source": [
        "If we try this final revision I think we're close enough (but certainly not perfect) in making sentences that vaguely \"look\" (but may not read) correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua62ievIRNJ9",
        "outputId": "644dc495-7b0c-4761-8bef-272abbb882f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Neither has a mathematical plane. These things are mere abstractions.” “That is all right,” said the Psychologist.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "' '.join(makesentence(8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgumB3hhRNJ9"
      },
      "source": [
        "Automate creating paragraphs. To accomplish this, we must string together a number of smaller units of text, ensuring that the final n-gram of the preceding text serves as the seed for the text that follows.\n",
        "\n",
        "In the code below, I define three new functions and modify the existing'make sentence' function:\n",
        "\n",
        "* `makenewseed` - This function takes the n-gram that ended the previous sentence and generates an n-gram to *start* the next new sentence. This directly addresses the requirement that the preceding text's final n-gram serve as the seed for the text that follows. The important property of the result is that it will be a seed n-gram that starts a new sentence correctly.\n",
        "\n",
        "* `makesentence` - This function operates in the same manner as the previous one, except that it accepts a seed n-gram as an argument and returns two values as a result: the new sentence and the final n-gram used to generate the sentence. As a result, we can chain these functions together and generate the seed n-gram for the next sentence using the final n-gram passed through `makenewseed`.\n",
        "\n",
        "* `makeparagraph` and `makechapter` - These two functions operate in a very similar manner. You give them a number to indicate how much of what they produce you require, as well as a seed n-gram to get them started. They both have a loop that will run for however long you specify to generate content before returning their result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZOSiG2ERNJ9"
      },
      "outputs": [],
      "source": [
        "def makenewseed(old_seed):\n",
        "    \"\"\"\n",
        "    Given an old seed (which closes a previous section), generate a new seed to start the next section.\n",
        "    \"\"\"\n",
        "    seed_ngram = old_seed\n",
        "    result = []\n",
        "    while len(result) < len(old_seed):  # Simply give N new words generated from the old_seed\n",
        "        next_word, seed_ngram = make_next_word(seed_ngram)\n",
        "        result.append(next_word)\n",
        "    return tuple(result)\n",
        "\n",
        "def makesentence(word_length, seed_ngram):\n",
        "    \"\"\"\n",
        "    Return a sentence of approximately word_length length.\n",
        "    \"\"\"\n",
        "    quote_flag = False\n",
        "    result = list(seed_ngram)\n",
        "    for word in result:\n",
        "        if word[0] == '\"':\n",
        "            quote_flag = True\n",
        "            break\n",
        "    while len(result) < word_length - 1:\n",
        "        next_word, seed_ngram = make_next_word(seed_ngram)\n",
        "        result.append(next_word)\n",
        "        if next_word[0] == '\"':\n",
        "            quote_flag = True\n",
        "        if next_word[-1] == '\"':\n",
        "            quote_flag = False\n",
        "    while True:\n",
        "        ending_words = [word for word in n_grams[seed_ngram] if word[-1] in stop_characters and word not in ignore_words]\n",
        "        if ending_words:\n",
        "            next_word = random.choice(ending_words)\n",
        "            new_ngram = list(seed_ngram[1:])\n",
        "            new_ngram.append(next_word)\n",
        "            seed_ngram = tuple(new_ngram)\n",
        "            result.append(next_word)\n",
        "            break\n",
        "        else:\n",
        "            next_word, seed_ngram = make_next_word(seed_ngram) \n",
        "            result.append(next_word)\n",
        "            if next_word[0] == '\"':\n",
        "                quote_flag = True\n",
        "            if next_word[-1] == '\"':\n",
        "                quote_flag = False\n",
        "    return tuple(result), seed_ngram  # Return the last n-gram used, to form the seed n-gram for the next sentence.\n",
        "\n",
        "\n",
        "def makeparagraph(number_of_sentences, seed_ngram):\n",
        "    \"\"\"\n",
        "    Generate a paragraph containing \"number_of_sentences\" sentences. Start the first sentence with the passed in n_gram.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    sentence_length = random.randint(3, 8)  # Vary the length of the sentences produced!\n",
        "    for i in range(number_of_sentences):\n",
        "        sentence, last_ngram = makesentence(sentence_length, seed_ngram)\n",
        "        result.append(' '.join(sentence))\n",
        "        seed_ngram = makenewseed(last_ngram)\n",
        "    return result, seed_ngram\n",
        "\n",
        "def makechapter(number_of_paragraphs, seed_ngram):\n",
        "    \"\"\"\n",
        "    Generate a chapter containing \"number_of_paragraphs\" paragraphs. Start te first sentence of the first paragraph with\n",
        "    the passed in n_gram.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    paragraph_length = random.randint(3, 8)  # Vary the number of sentences in a paragraph!\n",
        "    for i in range(number_of_paragraphs):\n",
        "        paragraph, last_ngram = makeparagraph(paragraph_length, seed_ngram)\n",
        "        result.append(' '.join(paragraph))\n",
        "        seed_ngram = last_ngram\n",
        "    return result, seed_ngram\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIa-gfloRNJ-"
      },
      "source": [
        "Creating a short 7 paragraph chapter using a seed n-gram that contains the opening three words of the novel. Here's some example output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_87-nCtARNJ-",
        "outputId": "463eaaaf-c52d-414d-c862-0ced905e1b68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Time Machine An Invention by H. G. Wells I. Introduction The Time Traveller smiled. “Are you so sure we can move freely in Space? Right and left we can go, backward and forward freely enough, and men always have done so. I admit we move freely in two dimensions. But how about up and down? Gravitation limits us there.” “Not exactly,” said the Medical Man.\n",
            "“Easier, far easier down than up.” “And you cannot move at all in Time, you cannot get away from my interrogations, so I determined, rather of necessity, to let them give their lessons in little doses when they felt inclined. And very little doses I found they were before long, for I never met people more indolent or more easily fatigued. VI. The Sunset of Mankind “A queer thing I soon discovered about my little hosts, and that was camphor. I found it in a sealed jar, that by chance, I suppose, had been really hermetically sealed. I fancied at first that it was inflammable and burnt with a good bright flame—was, in fact, an excellent candle—and I put it down.\n",
            "And then it came into my head by some at first incomprehensible remarks about the Dark Nights. It was not for some time that I could fancy myself flinging the whole dozen of them about like ninepins. But I made a discovery. In my trouser pocket were still some loose matches. The box must have leaked before it was lost.\n",
            "XIII. The Trap of the White Sphinx, into which the Morlocks had carried my machine. “For a time my brain went stagnant. Presently I got up and came through the passage here, limping, because my heel was still painful, and feeling sorely begrimed. I saw the thing was to be seen. Apparently the single house, and possibly even the household, had vanished. Here and there out of the ruin into the blinding sunlight.\n",
            "I fell upon my face. Even the soil smelt sweet and clean. Then I remember Weena kissing my hands and ears, and the voices of others among the Eloi. Then, for a time, and had, through the extinction of bacteria and fungi, lost ninety-nine hundredths of its force, was nevertheless, with extreme sureness if with extreme slowness at work again upon all its treasures. Here and there I found traces of the little mechanism which we had seen vanish from before our eyes. Parts were of nickel, parts of ivory, parts had certainly been filed or sawn out of rock crystal.\n",
            "The thing was generally complete, but the twisted crystalline bars lay unfinished upon the bench beside some sheets of drawings, and I took one up for a better look at it. Quartz it seemed to do him good: for he looked round the table, and the ghost of his old smile flickered across his face. “What on earth have you been up to, man?” said the Doctor. The Time Traveller smiled round at us. Then, still smiling faintly, and with his back to us began to fill his pipe.\n",
            "We stared at each other. After a time we ceased to do that, and looked only at the Time Machine. The fact is, the Time Traveller put the lamp down on the summit of the hillock, and watched this strange incredible company of blind things groping to and fro, and making uncanny noises to each other, I began the conversation. I pointed to the sun. At once a quaintly pretty little figure in chequered purple and white followed my gesture, and then astonished me by imitating the sound of thunder. “For a moment I was wet to the skin. ‘Fine hospitality,’ said I, ‘to a man who has travelled innumerable years to see you.’ “Presently I thought what a fool I was to get wet.\n"
          ]
        }
      ],
      "source": [
        "seed = next(find_ngrams(all_the_words_in_the_novel, N))  # Grabs the first n-gram.\n",
        "chapter, seed_ngram = makechapter(7, seed)\n",
        "print('\\n'.join(chapter))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Markov chains and N-grams.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}